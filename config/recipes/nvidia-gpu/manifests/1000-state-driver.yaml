apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
rules:
- apiGroups:
  - security.openshift.io
  resources:
  - securitycontextconstraints
  verbs:
  - use
  resourceNames:
  - privileged
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
subjects:
- kind: ServiceAccount
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
userNames:
- system:serviceaccount:{{.SpecialResource.Spec.Namespace}}:{{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}-entrypoint
data:
  entrypoint.sh: |-
    #!/bin/bash -x
    nvidia-driver init 

  version_id: "{{.ClusterVersionMajorMinor}}"
  rhel_version: "{{.OperatingSystemDecimal}}"
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
  name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
  annotations:
    openshift.io/scc: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
    specialresource.openshift.io/wait: "true"
    specialresource.openshift.io/wait-for-logs: "\\+ wait \\d+"
    specialresource.openshift.io/state: "driver-container"
    specialresource.openshift.io/driver-container-vendor: {{.SpecialResource.Spec.Node.Selector}}    
spec:
  selector:
    matchLabels:
      app: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        app: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
    spec:
      tolerations:
      - operator: Exists
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      serviceAccount: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
      serviceAccountName: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
      hostPID: true
      containers:
      - image: image-registry.openshift-image-registry.svc:5000/{{.SpecialResource.Spec.Namespace}}/{{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}:v{{.KernelVersion}}
        imagePullPolicy: Always
        name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}
        command: ["/bin/entrypoint.sh"]
        env: 
          - name: VERSION_ID
            valueFrom:
              configMapKeyRef:
                name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}-entrypoint
                key: version_id
          - name: RHEL_VERSION
            valueFrom:
              configMapKeyRef:
                name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}-entrypoint
                key: rhel_version
        securityContext:
          privileged: true
          seLinuxOptions:
            level: "s0"
        volumeMounts:
          - name: run-{{.SpecialResource.Name}}
            mountPath: /run/nvidia
            mountPropagation: Bidirectional
          - name: entrypoint
            mountPath: /bin/entrypoint.sh
            readOnly: true
            subPath: entrypoint.sh

      volumes:
        - name: run-{{.SpecialResource.Name}}
          hostPath:
            path: /run/nvidia
        - name: entrypoint
          configMap:
            defaultMode: 0700
            name: {{.SpecialResource.Name}}-{{.GroupName.DriverContainer}}-{{.OperatingSystemMajor}}-entrypoint
      nodeSelector:
        node-role.kubernetes.io/worker: ""
        {{.SpecialResource.Spec.Node.Selector}}: "true"
        feature.node.kubernetes.io/kernel-version.full: "{{.KernelVersion}}"
